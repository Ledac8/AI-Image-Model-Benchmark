{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Image Model Benchmark Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook provides a framework for comparing AI image generation models using standardized prompts and qualitative analysis.\n",
    "\n",
    "## How to Use This Notebook\n",
    "1. Manually generate images using each prompt with different AI models (DALL-E 3, Midjourney, Stable Diffusion)\n",
    "2. Save images to the appropriate folders in `/generated_images/`\n",
    "3. Use the cells below to load and compare images side-by-side\n",
    "4. Document your observations and insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Folder Structure\n",
    "Create these folders manually in your repository:\n",
    "- `generated_images/dalle-3/`\n",
    "- `generated_images/midjourney/`\n",
    "- `generated_images/stable-diffusion-xl/`\n",
    "\n",
    "Save your test images in these folders with consistent naming (e.g., `photorealism_dog.jpg`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your image directories\n",
    "image_dirs = {\n",
    "    'DALL-E 3': 'generated_images/dalle-3',\n",
    "    'Midjourney': 'generated_images/midjourney', \n",
    "    'Stable Diffusion XL': 'generated_images/stable-diffusion-xl'\n",
    "}\n",
    "\n",
    "# Check if directories exist\n",
    "for model, directory in image_dirs.items():\n",
    "    if os.path.exists(directory):\n",
    "        print(f\"✅ {model} directory found: {directory}\")\n",
    "        print(f\"   Images found: {len(os.listdir(directory))}\")\n",
    "    else:\n",
    "        print(f\"❌ {model} directory missing: {directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Comparison Function\n",
    "This function displays the same prompt generated by all three models for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_prompt(image_name, prompt_description):\n",
    "    \"\"\"\n",
    "    Compare the same prompt across all three models\n",
    "    \n",
    "    Args:\n",
    "        image_name (str): Base name of the image file (e.g., 'photorealism_dog')\n",
    "        prompt_description (str): The actual prompt used for context\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.suptitle(f'Prompt: \"{prompt_description}\"', fontsize=16, y=1.05)\n",
    "    \n",
    "    models = list(image_dirs.keys())\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        image_path = os.path.join(image_dirs[model], f\"{image_name}.jpg\")\n",
    "        \n",
    "        if os.path.exists(image_path):\n",
    "            img = Image.open(image_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f'{model}', fontsize=12)\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, f'Image not found\\n{image_path}', \n",
    "                       ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].set_title(f'{model}', fontsize=12)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"✅ Comparison function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Comparison\n",
    "When you have images, you can compare them like this:\n",
    "\n",
    "```python\n",
    "# compare_prompt('photorealism_dog', 'A photorealistic image of a wet German Shepherd playing in a sprinkler')\n",
    "```\n",
    "\n",
    "Remove the # symbol to run the comparison once you have images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative Analysis Template\n",
    "\n",
    "### Prompt: [Prompt Name]\n",
    "**Observations:**\n",
    "- **DALL-E 3:** [Your notes here]\n",
    "- **Midjourney:** [Your notes here] \n",
    "- **Stable Diffusion XL:** [Your notes here]\n",
    "\n",
    "**Key Takeaways:**\n",
    "- [Main insights about model differences]\n",
    "- [Surprising results or limitations]\n",
    "- [Implications for product marketing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Scoring\n",
    "Rate each model on key dimensions (1-5 scale):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an evaluation dataframe\n",
    "evaluation_data = {\n",
    "    'Model': ['DALL-E 3', 'Midjourney', 'Stable Diffusion XL'],\n",
    "    'Prompt_Adherence': [0, 0, 0],  # Fill in after testing\n",
    "    'Aesthetic_Quality': [0, 0, 0],\n",
    "    'Style_Range': [0, 0, 0],\n",
    "    'Text_Rendering': [0, 0, 0],\n",
    "    'Technical_Execution': [0, 0, 0]\n",
    "}\n",
    "\n",
    "df_evaluation = pd.DataFrame(evaluation_data)\n",
    "print(\"Evaluation framework ready!\")\n",
    "print(\"\\nFill in your scores (1-5) after testing:\")\n",
    "df_evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
